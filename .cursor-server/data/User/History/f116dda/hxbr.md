# Qwen-32B Vision Model with CogVLM Integration

## Overview
This project implements a multimodal chat interface that combines the Qwen-32B language model with vision capabilities through CogVLM integration. It enables interactive conversations with both text and image inputs.

## Features
- Multimodal chat interface supporting both text and image inputs
- Integration with CogVLM for vision processing
- Support for GPU acceleration with CUDA
- Progress tracking during model loading
- Configurable model parameters

## Prerequisites
- Python 3.10+
- CUDA capable GPU (recommended)
- NVIDIA drivers and CUDA toolkit installed

## Installation

1. Clone the repository: 